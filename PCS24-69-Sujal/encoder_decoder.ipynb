{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image,ImageOps\n",
    "from PIL import ImageDraw \n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout, GRU\n",
    "import random\n",
    "import datetime\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sashrikasurya/Documents/Medical-Report-Generator'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.dirname(os.path.realpath('__file__'))\n",
    "dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dirname+\"/data/traindata.csv\",nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CXR3080_IM-1440</td>\n",
       "      <td>CXR3080_IM-1440-1001</td>\n",
       "      <td>CXR3080_IM-1440-1002</td>\n",
       "      <td>startseq the cavity and the left upper lobe ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CXR2721_IM-1183</td>\n",
       "      <td>CXR2721_IM-1183-1001</td>\n",
       "      <td>CXR2721_IM-1183-2001</td>\n",
       "      <td>startseq heart size at the upper limits of nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CXR2160_IM-0778</td>\n",
       "      <td>CXR2160_IM-0778-1001</td>\n",
       "      <td>CXR2160_IM-0778-2001</td>\n",
       "      <td>startseq the cardiomediastinal silhouette is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CXR3586_IM-1764</td>\n",
       "      <td>CXR3586_IM-1764-1001</td>\n",
       "      <td>CXR3586_IM-1764-2001</td>\n",
       "      <td>startseq the heart is mildly enlarged the medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CXR3139_IM-1476</td>\n",
       "      <td>CXR3139_IM-1476-1001</td>\n",
       "      <td>CXR3139_IM-1476-2001</td>\n",
       "      <td>startseq no focal areas of consolidation no pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       patient_id             image1_id             image2_id  \\\n",
       "0           0  CXR3080_IM-1440  CXR3080_IM-1440-1001  CXR3080_IM-1440-1002   \n",
       "1           1  CXR2721_IM-1183  CXR2721_IM-1183-1001  CXR2721_IM-1183-2001   \n",
       "2           2  CXR2160_IM-0778  CXR2160_IM-0778-1001  CXR2160_IM-0778-2001   \n",
       "3           3  CXR3586_IM-1764  CXR3586_IM-1764-1001  CXR3586_IM-1764-2001   \n",
       "4           4  CXR3139_IM-1476  CXR3139_IM-1476-1001  CXR3139_IM-1476-2001   \n",
       "\n",
       "                                              report  \n",
       "0  startseq the cavity and the left upper lobe ha...  \n",
       "1  startseq heart size at the upper limits of nor...  \n",
       "2  startseq the cardiomediastinal silhouette is w...  \n",
       "3  startseq the heart is mildly enlarged the medi...  \n",
       "4  startseq no focal areas of consolidation no pl...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(dirname+\"/data/testdata.csv\",nrows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CXR1306_IM-0200</td>\n",
       "      <td>CXR1306_IM-0200-2001</td>\n",
       "      <td>CXR1306_IM-0200-3001</td>\n",
       "      <td>startseq the  examination consists of frontal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CXR1786_IM-0512</td>\n",
       "      <td>CXR1786_IM-0512-1001</td>\n",
       "      <td>CXR1786_IM-0512-2001</td>\n",
       "      <td>startseq the lungs are clear bilaterally speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CXR2072_IM-0706</td>\n",
       "      <td>CXR2072_IM-0706-1001</td>\n",
       "      <td>CXR2072_IM-0706-2001</td>\n",
       "      <td>startseq stable nonenlarged cardiomediastinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CXR467_IM-2095</td>\n",
       "      <td>CXR467_IM-2095-2001</td>\n",
       "      <td>CXR467_IM-2095-2001</td>\n",
       "      <td>startseq lungs are clear bilaterally cardiac a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CXR3087_IM-1444</td>\n",
       "      <td>CXR3087_IM-1444-1001</td>\n",
       "      <td>CXR3087_IM-1444-2001</td>\n",
       "      <td>startseq the heart is enlarged the mediastinal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       patient_id             image1_id             image2_id  \\\n",
       "0           0  CXR1306_IM-0200  CXR1306_IM-0200-2001  CXR1306_IM-0200-3001   \n",
       "1           1  CXR1786_IM-0512  CXR1786_IM-0512-1001  CXR1786_IM-0512-2001   \n",
       "2           2  CXR2072_IM-0706  CXR2072_IM-0706-1001  CXR2072_IM-0706-2001   \n",
       "3           3   CXR467_IM-2095   CXR467_IM-2095-2001   CXR467_IM-2095-2001   \n",
       "4           4  CXR3087_IM-1444  CXR3087_IM-1444-1001  CXR3087_IM-1444-2001   \n",
       "\n",
       "                                              report  \n",
       "0  startseq the  examination consists of frontal ...  \n",
       "1  startseq the lungs are clear bilaterally speci...  \n",
       "2  startseq stable nonenlarged cardiomediastinal ...  \n",
       "3  startseq lungs are clear bilaterally cardiac a...  \n",
       "4  startseq the heart is enlarged the mediastinal...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0',axis='columns',inplace=True)\n",
    "test.drop('Unnamed: 0',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR3080_IM-1440</td>\n",
       "      <td>CXR3080_IM-1440-1001</td>\n",
       "      <td>CXR3080_IM-1440-1002</td>\n",
       "      <td>startseq the cavity and the left upper lobe ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR2721_IM-1183</td>\n",
       "      <td>CXR2721_IM-1183-1001</td>\n",
       "      <td>CXR2721_IM-1183-2001</td>\n",
       "      <td>startseq heart size at the upper limits of nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR2160_IM-0778</td>\n",
       "      <td>CXR2160_IM-0778-1001</td>\n",
       "      <td>CXR2160_IM-0778-2001</td>\n",
       "      <td>startseq the cardiomediastinal silhouette is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR3586_IM-1764</td>\n",
       "      <td>CXR3586_IM-1764-1001</td>\n",
       "      <td>CXR3586_IM-1764-2001</td>\n",
       "      <td>startseq the heart is mildly enlarged the medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR3139_IM-1476</td>\n",
       "      <td>CXR3139_IM-1476-1001</td>\n",
       "      <td>CXR3139_IM-1476-2001</td>\n",
       "      <td>startseq no focal areas of consolidation no pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id             image1_id             image2_id  \\\n",
       "0  CXR3080_IM-1440  CXR3080_IM-1440-1001  CXR3080_IM-1440-1002   \n",
       "1  CXR2721_IM-1183  CXR2721_IM-1183-1001  CXR2721_IM-1183-2001   \n",
       "2  CXR2160_IM-0778  CXR2160_IM-0778-1001  CXR2160_IM-0778-2001   \n",
       "3  CXR3586_IM-1764  CXR3586_IM-1764-1001  CXR3586_IM-1764-2001   \n",
       "4  CXR3139_IM-1476  CXR3139_IM-1476-1001  CXR3139_IM-1476-2001   \n",
       "\n",
       "                                              report  \n",
       "0  startseq the cavity and the left upper lobe ha...  \n",
       "1  startseq heart size at the upper limits of nor...  \n",
       "2  startseq the cardiomediastinal silhouette is w...  \n",
       "3  startseq the heart is mildly enlarged the medi...  \n",
       "4  startseq no focal areas of consolidation no pl...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1306_IM-0200</td>\n",
       "      <td>CXR1306_IM-0200-2001</td>\n",
       "      <td>CXR1306_IM-0200-3001</td>\n",
       "      <td>startseq the  examination consists of frontal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1786_IM-0512</td>\n",
       "      <td>CXR1786_IM-0512-1001</td>\n",
       "      <td>CXR1786_IM-0512-2001</td>\n",
       "      <td>startseq the lungs are clear bilaterally speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR2072_IM-0706</td>\n",
       "      <td>CXR2072_IM-0706-1001</td>\n",
       "      <td>CXR2072_IM-0706-2001</td>\n",
       "      <td>startseq stable nonenlarged cardiomediastinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR467_IM-2095</td>\n",
       "      <td>CXR467_IM-2095-2001</td>\n",
       "      <td>CXR467_IM-2095-2001</td>\n",
       "      <td>startseq lungs are clear bilaterally cardiac a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR3087_IM-1444</td>\n",
       "      <td>CXR3087_IM-1444-1001</td>\n",
       "      <td>CXR3087_IM-1444-2001</td>\n",
       "      <td>startseq the heart is enlarged the mediastinal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id             image1_id             image2_id  \\\n",
       "0  CXR1306_IM-0200  CXR1306_IM-0200-2001  CXR1306_IM-0200-3001   \n",
       "1  CXR1786_IM-0512  CXR1786_IM-0512-1001  CXR1786_IM-0512-2001   \n",
       "2  CXR2072_IM-0706  CXR2072_IM-0706-1001  CXR2072_IM-0706-2001   \n",
       "3   CXR467_IM-2095   CXR467_IM-2095-2001   CXR467_IM-2095-2001   \n",
       "4  CXR3087_IM-1444  CXR3087_IM-1444-1001  CXR3087_IM-1444-2001   \n",
       "\n",
       "                                              report  \n",
       "0  startseq the  examination consists of frontal ...  \n",
       "1  startseq the lungs are clear bilaterally speci...  \n",
       "2  startseq stable nonenlarged cardiomediastinal ...  \n",
       "3  startseq lungs are clear bilaterally cardiac a...  \n",
       "4  startseq the heart is enlarged the mediastinal...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (200, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train['patient_id'], test['patient_id']\n",
    "y_train, y_test = train['report'], test['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,), (200,), (200,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirname+'/features/list_train_features.pkl', 'rb') as f:\n",
    "    train_feat_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirname+'/features/list_test_features.pkl', 'rb') as f:\n",
    "    test_feat_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dirname+'/glove.840B.300d.pkl','rb') # 300d glove vectors  \n",
    "glove_vectors = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index.keys()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in glove_vectors.keys():\n",
    "        vec = glove_vectors[word]\n",
    "        embedding_matrix[i] = vec\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_feat_list,y_train))\n",
    "train_dataset = train_dataset.shuffle(300).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_feat_list,y_test))\n",
    "test_dataset = test_dataset.shuffle(300).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(images,reports_unpadded):\n",
    "    imgs = []\n",
    "    input_reports = []\n",
    "    output_reports = []\n",
    "    for i in range(len(images)):\n",
    "        sequence=[] \n",
    "        for rep in reports_unpadded[i].split(\" \"):\n",
    "            if rep in tokenizer.word_index.keys():\n",
    "                sequence.append(tokenizer.word_index[rep])\n",
    "        for j in range(1,len(sequence)):\n",
    "            in_seq = sequence[:j]          \n",
    "            out_seq = sequence[j]            \n",
    "            out_seq = tf.keras.utils.to_categorical(out_seq, num_classes=vocab_size)\n",
    "            imgs.append(images[i])            \n",
    "            input_reports.append(in_seq)            \n",
    "            output_reports.append(out_seq)\n",
    "        \n",
    "    return np.array(imgs), np.array(input_reports), np.array(output_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='auto')\n",
    "def maskedLoss(y_true, y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    loss_ = loss_function(y_true, y_pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ = loss_*mask\n",
    "    loss_ = tf.reduce_mean(loss_)\n",
    "    return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 80, 300)      321600      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (LSTM)                    (None, 80, 256)      570368      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Images (InputLayer)             [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (LSTM)                    (None, 512)          1574912     LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense (Dense)               (None, 512)          1049088     Images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           LSTM2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512)          0           enc_dense[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          262656      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1072)         549936      dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,328,560\n",
      "Trainable params: 4,006,960\n",
      "Non-trainable params: 321,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1=Input(shape=(2048),name=\"Images\")\n",
    "encoder_out=Dense(512,activation=\"relu\",name=\"enc_dense\")(input_1)\n",
    "\n",
    "\n",
    "#decoder model\n",
    "input_text=Input(shape=(max_len),name=\"text\")\n",
    "\n",
    "embedding_out=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=300,input_length=max_len,mask_zero=True,trainable=False,weights=[embedding_matrix])(input_text)\n",
    "\n",
    "lstm_out1= LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(embedding_out)\n",
    "\n",
    "lstm_out2= LSTM(units=512, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")(lstm_out1) \n",
    "\n",
    "x=Dropout(0.35)(lstm_out2)\n",
    "add=tf.keras.layers.Add()([encoder_out, x])\n",
    "  \n",
    "x=Dense(512,kernel_initializer=tf.keras.initializers.he_normal(seed=1),activation=\"relu\")(add)\n",
    "\n",
    "x1=Dropout(0.25)(x)\n",
    "\n",
    "x1=Dense(vocab_size,activation=\"softmax\")(x1)\n",
    "#encoder_decoder_model\n",
    "encoder_decoder=Model(inputs=[input_1,input_text],outputs=x1)\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.compile(optimizer=\"Adam\", loss = maskedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1\n",
      "Training Loss: 0.004879826228275444\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('EPOCH : ',epoch+1)\n",
    "    batch_loss_train = 0\n",
    "    \n",
    "    for img, report in train_dataset:        \n",
    "        r1 = [word.decode('utf-8') for word in np.array(report)]  \n",
    "        img_input, rep_input, output_word = load_data(img.numpy(), r1)\n",
    "        rep_input = tf.keras.preprocessing.sequence.pad_sequences(rep_input, maxlen=80, padding='post')\n",
    "        img_input=tf.reshape(img_input,shape=(img_input.shape[0],img_input.shape[-1]))        \n",
    "        loss = encoder_decoder.train_on_batch([img_input, rep_input], output_word)        \n",
    "        batch_loss_train += loss\n",
    "\n",
    "    train_loss = batch_loss_train/(len(y_train)//15)\n",
    "    print('Training Loss: {}'.format(train_loss))\n",
    "    \n",
    "encoder_decoder.save_weights('encoder_decoder_epoch_'+ str(epoch+1) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(img):\n",
    "    img=img_to_array(img)\n",
    "    img=preprocess_input(img)\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    img=img/255.0\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "image_shape= (224,224,3)\n",
    "mod2=DenseNet121(include_top=False,input_shape=image_shape,pooling=\"avg\")\n",
    "las2=Dense(14,\"sigmoid\")(mod2.output)\n",
    "\n",
    "mod2=Model(inputs=mod2.input,outputs=las2)\n",
    "mod2.load_weights(dirname+\"/features/chexnet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chexnet_model=Model(inputs=mod2.inputs,outputs=mod2.layers[-2].output,name=\"Chexnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1= tf.keras.Input(shape=(224,224,3),name=\"image_1_features\")\n",
    "image_2= tf.keras.Input(shape=(224,224,3),name=\"image_2_features\")\n",
    "image_1_out=final_chexnet_model(image_1)\n",
    "image_2_out=final_chexnet_model(image_2)\n",
    "conc=tf.keras.layers.Concatenate(axis=-1)([image_1_out,image_2_out])\n",
    "feature_extraction_model=Model(inputs=[image_1,image_2],outputs=conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.load_weights(dirname+'/encoder_decoder_epoch_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(image1,image2):\n",
    "    image_features=feature_extraction_model([image1,image2])\n",
    "    output_report=''\n",
    "    input_rep= 'startseq'\n",
    "    image_features=tf.reshape(image_features,shape=(-1,image_features.shape[-1]))\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        input_tokens = [tokenizer.word_index[w] for w in input_rep.split()]\n",
    "        input_padded = tf.keras.preprocessing.sequence.pad_sequences([input_tokens],max_len, padding='post')\n",
    "        results = encoder_decoder.predict([image_features,input_padded])\n",
    "        arg = np.argmax(results[0]) \n",
    "        if tokenizer.index_word[arg]=='endseq':\n",
    "            output_report+=tokenizer.index_word[arg]+\" \"\n",
    "            break\n",
    "        else:\n",
    "            input_rep = input_rep + ' ' + tokenizer.index_word[arg]\n",
    "            output_report = output_report+tokenizer.index_word[arg]+\" \"\n",
    "    return output_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img1\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(dirname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/sample/CXR1009_IM-0010-1001\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m img2\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(dirname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/sample/CXR1009_IM-0010-1001\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m imshow(np\u001b[38;5;241m.\u001b[39masarray(img1))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "img1=Image.open(dirname+'/data/sample/CXR1009_IM-0010-1001'+'.png')\n",
    "img2=Image.open(dirname+'/data/sample/CXR1009_IM-0010-1001'+'.png')\n",
    "\n",
    "imshow(np.asarray(img1))\n",
    "img1=img_preprocess(img1)\n",
    "img2=img_preprocess(img2)\n",
    "result=evaluation(img1,img2) \n",
    "actual=y_test[0]\n",
    "\n",
    "print(\"Actual Report: \",actual)\n",
    "print(\"Generated Report: \",result) \n",
    "print(\"BLEU SCORE IS: \",sentence_bleu(actual,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img1=Image.open(dirname+'/data/sample/CXR1026_IM-0021-2002'+'.png')\n",
    "img2=Image.open(dirname+'/data/sample/CXR1026_IM-0021-2002'+'.png')\n",
    "\n",
    "imshow(np.asarray(img1))\n",
    "img1=img_preprocess(img1)\n",
    "img2=img_preprocess(img2)\n",
    "result=evaluation(img1,img2) \n",
    "actual=y_test[4]\n",
    "print(\"Actual Report: \",actual)\n",
    "print(\"Generated Report: \",result) \n",
    "print(\"BLEU SCORE IS: \",sentence_bleu(actual,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\1997a\\Desktop\\MedGen-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convert it to a TensorFlow model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m---> 12\u001b[0m logits \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(output_units)(input_tensor)\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_tensor, outputs\u001b[38;5;241m=\u001b[39mlogits)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_units' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained scikit-learn model\n",
    "model = joblib.load(\"C:/Users/1997a/Desktop/MedGen-main/features/list_train_features.pkl\")\n",
    "\n",
    "# Define the input shape based on your image data\n",
    "input_shape = ( 224,224,3)  # Replace with the actual image dimensions\n",
    "\n",
    "# Convert it to a TensorFlow model\n",
    "input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "logits = tf.keras.layers.Dense(output_units)(input_tensor)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_tensor, outputs\u001b[38;5;241m=\u001b[39moutput_tensor)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 14\u001b[0m tf_model \u001b[38;5;241m=\u001b[39m scikit_learn_to_tf(scikit_learn_model)\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mscikit_learn_to_tf\u001b[1;34m(scikit_model)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscikit_learn_to_tf\u001b[39m(scikit_model):\n\u001b[0;32m      9\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m---> 10\u001b[0m     output_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(scikit_model\u001b[38;5;241m.\u001b[39mpredict)(input_tensor)\n\u001b[0;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_tensor, outputs\u001b[38;5;241m=\u001b[39moutput_tensor)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load your scikit-learn model from the .pkl file\n",
    "scikit_learn_model = joblib.load(\"C:/Users/1997a/Desktop/MedGen-main/features/list_train_features.pkl\")\n",
    "input_shape = (224, 224,3)\n",
    "import tensorflow as tf\n",
    "\n",
    "def scikit_learn_to_tf(scikit_model):\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "    output_tensor = tf.keras.layers.Lambda(scikit_model.predict)(input_tensor)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    return model\n",
    "\n",
    "tf_model = scikit_learn_to_tf(scikit_learn_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
